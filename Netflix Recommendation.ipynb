{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfac Netflix Content-Based Recommendation System\n\nThis notebook builds a content-based filtering recommendation engine using the Netflix dataset.\n\n**Pipeline:**\n1. Data Loading & Exploration\n2. Preprocessing & Cleaning\n3. Feature Engineering\n4. TF-IDF Model\n5. Recommendation Function\n6. Evaluation (Precision@K)\n7. Insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. \ud83d\udce6 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel, cosine_similarity\nimport difflib\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. \ud83d\udcc2 Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"netflix_data.csv\")\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Columns: {list(df.columns)}\")\ndf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic info\nprint(\"Dataset Info:\")\ndf.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missing values summary\nmissing = df.isnull().sum()\nmissing_pct = (missing / len(df) * 100).round(2)\nmissing_df = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_pct})\nprint(\"Missing Values:\")\nprint(missing_df[missing_df['Missing Count'] > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. \ud83d\udcca Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Content type distribution\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\ndf['type'].value_counts().plot(kind='bar', ax=axes[0], color=['#E50914', '#564d4d'])\naxes[0].set_title('Movies vs TV Shows', fontsize=14)\naxes[0].set_xlabel('Type')\naxes[0].set_ylabel('Count')\naxes[0].tick_params(axis='x', rotation=0)\n\ndf['rating'].value_counts().plot(kind='bar', ax=axes[1], color=sns.color_palette(\"Reds_r\", 17))\naxes[1].set_title('Content Rating Distribution', fontsize=14)\naxes[1].set_xlabel('Rating')\naxes[1].set_ylabel('Count')\naxes[1].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Content added over the years\ndf_temp = df.copy()\ndf_temp['date_added'] = pd.to_datetime(df_temp['date_added'], errors='coerce')\ndf_temp['year_added'] = df_temp['date_added'].dt.year\n\nyear_type = df_temp.groupby(['year_added', 'type']).size().unstack(fill_value=0)\nyear_type.plot(figsize=(12, 5), color=['#E50914', '#564d4d'])\nplt.title('Netflix Content Added Per Year by Type', fontsize=14)\nplt.xlabel('Year')\nplt.ylabel('Number of Titles')\nplt.legend(title='Type')\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 10 genres\nmain_genre = df['listed_in'].str.split(',').str[0].str.strip()\ntop_genres = main_genre.value_counts().head(10)\n\ntop_genres.plot(kind='barh', color=plt.cm.Reds_r(np.linspace(0.3, 0.9, 10)), figsize=(10, 6))\nplt.title('Top 10 Netflix Genres (Primary Genre)', fontsize=14)\nplt.xlabel('Number of Titles')\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Keyword frequency in descriptions\nkeywords = {'love': 'Romantic', 'murder': 'Crime', 'family': 'Family', 'war': 'War', 'life': 'Drama'}\n\nkeyword_counts = {v: df['description'].str.lower().str.contains(k).sum() for k, v in keywords.items()}\npd.Series(keyword_counts).plot(kind='bar', color=plt.cm.tab10.colors[:5], figsize=(8, 4))\nplt.title('Description Keyword Frequency', fontsize=13)\nplt.ylabel('Count')\nplt.tick_params(axis='x', rotation=0)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. \ud83d\udd27 Data Preprocessing\n\nWe drop rows with missing critical columns (director, cast, description), then build a clean working copy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Work on a clean copy \u2014 avoids SettingWithCopyWarning\ndf1 = df.dropna(subset=['director', 'cast', 'description', 'listed_in']).copy()\n\nprint(f\"Original rows : {len(df)}\")\nprint(f\"After cleaning: {len(df1)}\")\nprint(f\"Rows removed  : {len(df) - len(df1)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check no remaining nulls in key columns\nprint(\"Remaining nulls in key columns:\")\nprint(df1[['director', 'cast', 'description', 'listed_in', 'title', 'type']].isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert date_added and extract year\ndf1['date_added'] = pd.to_datetime(df1['date_added'], errors='coerce')\ndf1['year_added'] = df1['date_added'].dt.year\n\n# Map ratings to numeric\nrating_map = {'G': 1, 'TV-Y': 1, 'TV-Y7': 1, 'PG': 2, 'TV-G': 2,\n              'PG-13': 3, 'TV-14': 4, 'R': 5, 'NC-17': 5, 'TV-MA': 6}\ndf1['rating_num'] = df1['rating'].map(rating_map)\n\n# Reset index for clean positional access\ndf1 = df1.reset_index(drop=True)\nprint(\"Preprocessing complete!\")\ndf1[['title', 'type', 'rating', 'rating_num', 'year_added']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. \ud83e\udde0 Feature Engineering \u2014 TF-IDF\n\nWe combine `description`, `listed_in`, `director`, and `cast` into a single text feature for vectorization.\n\n> **Why these fields?** Together they capture *what the content is about*, *what genre it belongs to*, *who made it*, and *who's in it*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the combined text feature using all relevant columns\ndf1['tfidf_feature'] = (\n    df1['listed_in'].fillna('') + ' ' +\n    df1['description'].fillna('') + ' ' +\n    df1['cast'].fillna('') + ' ' +\n    df1['director'].fillna('')\n).str.lower()\n\ndf1['tfidf_feature'].head(3).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit TF-IDF Vectorizer\ntfidf = TfidfVectorizer(stop_words='english', max_features=15000)\nX_tfidf = tfidf.fit_transform(df1['tfidf_feature'])\n\nprint(f\"TF-IDF matrix shape: {X_tfidf.shape}\")\nprint(f\"Vocabulary size    : {len(tfidf.vocabulary_)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build a lowercase title \u2192 row index lookup\nindices_lower = pd.Series(df1.index, index=df1['title'].str.lower().str.strip()).drop_duplicates()\nprint(f\"Index built for {len(indices_lower)} titles.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. \ud83c\udfaf Recommendation Function\n\nThe function:\n- Matches same type (Movie / TV Show)\n- Prioritises genre overlap (`primary` bucket)\n- Falls back to same-type items without genre overlap (`secondary` bucket)\n- Includes fuzzy title matching for typos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recommend_tfidf_enhanced(title, topn=10):\n    \"\"\"\n    Returns top-N content-based recommendations for a given Netflix title.\n\n    Parameters\n    ----------\n    title : str\n        Movie or TV show title (case-insensitive).\n    topn : int\n        Number of recommendations to return (default 10).\n\n    Returns\n    -------\n    pd.DataFrame or str\n    \"\"\"\n    title_key = title.strip().lower()\n\n    # --- Fuzzy match if exact title not found ---\n    if title_key not in indices_lower:\n        close = difflib.get_close_matches(title_key, indices_lower.index.tolist(), n=1, cutoff=0.6)\n        if close:\n            print(f\"\u26a0\ufe0f  '{title}' not found. Did you mean: '{close[0].title()}'? Using that.\")\n            title_key = close[0]\n        else:\n            return f\"\u274c Title not found: '{title}'. Please check the spelling.\"\n\n    original_idx = int(indices_lower[title_key])\n    orig_type    = df1.at[original_idx, 'type']\n    orig_genres  = set(g.strip().lower() for g in str(df1.at[original_idx, 'listed_in']).split(','))\n\n    # --- Compute cosine similarities ---\n    sims      = linear_kernel(X_tfidf[original_idx], X_tfidf).flatten()\n    sim_order = sims.argsort()[::-1]\n\n    primary   = []  # same type + genre overlap\n    secondary = []  # same type, no genre overlap\n\n    for pos_idx in sim_order:\n        if pos_idx == original_idx:\n            continue\n        if str(df1.at[pos_idx, 'type']).strip() != str(orig_type).strip():\n            continue\n\n        cand_genres = set(g.strip().lower() for g in str(df1.at[pos_idx, 'listed_in']).split(','))\n        score = float(sims[pos_idx])\n\n        if orig_genres & cand_genres:\n            primary.append((pos_idx, score))\n        else:\n            secondary.append((pos_idx, score))\n\n        if len(primary) >= topn:\n            break\n\n    final = primary[:topn]\n    if len(final) < topn:\n        final += secondary[:topn - len(final)]\n\n    rows = []\n    for idx, sc in final:\n        rows.append({\n            'title'      : df1.at[idx, 'title'],\n            'type'       : df1.at[idx, 'type'],\n            'listed_in'  : df1.at[idx, 'listed_in'],\n            'rating'     : df1.at[idx, 'rating'],\n            'release_year': df1.at[idx, 'release_year'],\n            'description': df1.at[idx, 'description'],\n            'score'      : round(sc, 4)\n        })\n\n    return pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. \ud83d\udccf Evaluation \u2014 Precision@K\n\nPrecision@K measures what fraction of the top-K recommendations share at least one genre with the input title."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def precision_at_k(title, k=10):\n    \"\"\"\n    Computes Precision@K for a given title based on genre overlap.\n    \"\"\"\n    recs = recommend_tfidf_enhanced(title, k)\n\n    if isinstance(recs, str):\n        print(recs)\n        return None\n\n    # Use df1 (not raw df) for genre lookup \u2014 consistent with recommendation\n    match = df1[df1['title'].str.lower() == title.strip().lower()]\n    if match.empty:\n        return None\n\n    original_genres = set(g.strip() for g in match.iloc[0]['listed_in'].split(','))\n    match_count = 0\n\n    for g in recs['listed_in']:\n        if any(x.strip() in original_genres for x in g.split(',')):\n            match_count += 1\n\n    precision = match_count / k\n    print(f\"Precision@{k} for '{title}': {precision:.2f}  ({match_count}/{k} recommendations matched genre)\")\n    return precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batch evaluation across several titles\ntest_titles = ['Jeans', 'Zodiac', 'Zombieland', 'The Starling', 'Sankofa']\n\nresults = {}\nfor t in test_titles:\n    p = precision_at_k(t, k=10)\n    if p is not None:\n        results[t] = p\n\nprint()\nprint(\"--- Average Precision@10 ---\")\navg = sum(results.values()) / len(results)\nprint(f\"  {avg:.2f} across {len(results)} titles\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. \ud83d\udd0d Interactive Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "name = input(\"Enter a movie or TV show title: \")\nrecs = recommend_tfidf_enhanced(name, topn=6)\nprint()\nprint(f\"Top 6 recommendations for '{name}':\")\nprint(recs[['title', 'type', 'listed_in', 'rating', 'release_year', 'score']].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show precision for the queried title\nprecision_at_k(name, k=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. \ud83d\udca1 Insights\n\n1. **Drama dominates Netflix** \u2014 Dramas are by far the most represented genre, followed by Comedies and Documentaries.\n2. **TV Show growth post-2015** \u2014 Netflix significantly ramped up TV Show additions after 2015, reflecting its shift to original series.\n3. **TF-IDF on combined features beats description-only** \u2014 Including `listed_in`, `cast`, and `director` alongside `description` improves semantic similarity and genre precision.\n4. **Precision@10 typically 0.6\u20130.9** \u2014 Genre-filtered recommendations are quite accurate; most top-10 results share at least one genre with the input.\n5. **Limitation** \u2014 This is a content-based system; it has no user preference or collaborative signals. Two users watching the same movie get identical recommendations.\n\n### Future Improvements\n- Add collaborative filtering (user ratings data) for personalisation\n- Incorporate `release_year` era bucketing to prefer similar-era content\n- Deploy as a simple Streamlit or Flask web app\n"
      ]
    }
  ]
}